\begin{savequote}[75mm] 
There will come a time when it isn't 'They're spying on me through my phone' anymore. Eventually, it will be 'My phone is spying on me'.
\qauthor{Philip K. Dick} 
\end{savequote}

\chapter{Web tracking: how advertising networks collect users' browsing patterns}

\newthought{In the early age of the Internet users enjoyed a large level of anonymity.} At the time web pages were just hypertext documents; almost no personalisation of the user experience was offered. The Web today has evolved as a world wide distributed system following specific architectural paradigms. On the web now, an enormous quantity of user generated data is shared and consumed by a network of applications and services, reasoning upon users expressed preferences and their social and physical connections. Advertising networks follow users' browsing habits while they surf the web, continuously collecting their traces and surfing patterns, since advertising sustains the business model of many websites and applications. Efficient and successful advertising relies on predicting users' actions and tastes to suggest a range of products to buy. Both service providers and advertisers try to track users' behaviour across their product network. For application providers this means tracking users' actions within their platform. For third-party services \emph{following} users, means being able to track them across different websites and applications. It is well known how, while surfing the Web, users leave traces regarding their identity in the form of activity patterns and unstructured data. These data constitute what is called the user's on-line footprint. We analyse how advertising networks build and collect users footprints and how the suggested advertising reacts to changes in the user behaviour.

\section{Background}

Websites use \emph{personalisation services} to provide a tailored experience to their visitors. In order to make their product more personal to the single users they need to keep profiles of their users, collect their in page reading activities and eventually their preferences. This data is then shared to third-party services, accessed and analysed without users? direct consent. Furthermore, records of users? activities are used for different purposes, most unknown to the end user, such as marketing or to provide analytics services back to the original website or application.
Among the data analysed by websites are also included user preferences and social connections. These can be obtained by tracking users across different applications and sites through cookies or open web sessions. Even if the user does not accept cookies or is not logged into a service account, such as their Google, Twitter or Facebook accounts, the web page and third-party services can still try to profile them by using third-party HTTP requests, among other techniques. Within the HTTP request various selectors can be included to communicate user preferences or particular features, in the form of URL variables. Features that might be used by advertising networks and malicious trackers include personalised language or fonts settings, browser extensions, in page keywords, battery charge and status, and so on. These features are then used to identify individual users by restricting the pool of possible candidates among all the visitors in a certain time frame, location, profile of interests. Unique users can then be distinguished across multiple devices or sessions.

In this chapter, have observed how users are tracked across the Web and how the displayed advertising is tailored even after they have visited a few websites with a certain interest bias. In previous work~\cite{puglisi2016web}~\cite{puglisi2015you} we analysed how third-party advertising services are able to profile users on a short series of websites visited and how these are able to \emph{follow} users while they surf the web.
In our study we analyse how the user profile detected by advertising services can be used to estimate the user privacy risk on a certain network. We analyse how advertising networks identify a user and start tracking them, by considering keywords contained in the web-page and understanding the underlying network structure of tracked domains. We measure the distance between the observed user profile and the actual user profile, by categorising the set of keywords contained in web pages and by capturing third-party HTTP requests. We introduce a set of metrics to express this distance between the two profiles. 

It is important to note that we have considered the case for which users are not registering, neither connecting any external account, as it could be the case with services like: Facebook, Google+, Twitter, and so on. In such scenario we have measured how these networks still attempt to track the user by sending user information through HTTP requests to their services.

We present a model of the user profile that is able to capture how each website and tracking network categorise their activities in terms of interests and interactions. 

Therefore, we analyse how much information is sent by each page visited to third-party services by measuring the partial user profile and the actual user profile. The partial user profile is what the website and third-party services know about the user. The actual user profile is instead the full profile measured at the end of the series of page visited.

We then, introduce a set of metrics to express the relationship between the partial and the actual user profile.

Hence, we profile third-party HTTP calls sent by Facebook tracking services and compare this to the the user actual profile.

Finally, we model user on-line footprints as a graph of the actions generated by each user and analyse the resulting graph structure, identifying known malicious trackers.

\section{Modelling the user profile}
\label{sec:mod-profile}
Each time the user visits a new page, we aggregate the page keywords and build what we consider the user's profile of interests (Figure ~\ref{abs-profile}). We consider a tractable model of the user profile as a probability mass function (PMF), as proposed in~\cite{Parra12DKE,Parra12TKDE}, to express how each keyword contributes to expose how many times the user has indirectly expressed a preference toward a specific category. We consider that the user expresses a preference when they visit a webpage categorised with certain keywords. This model follows the intuitive assumption that a particular category is weighted according to the number of times this has been counted in the user profile.

We define the profile of a user as the PMF $p = (p_1,\ldots, p_L)$, conceptually a histogram of relative frequencies of tags across the set of tag categories $\mathcal{T}$. This means that we group tags around interests using top level categories as defined by the Open Directory Project (DMOZ)~\cite{a22}.
The user profile is calculated at the end of the series of website visited by the user. Similarly we define the partial user profile at moment as this is known to the advertising network as  $\hat{p} = (\hat{p}_1,\ldots, \hat{p}_L)$. 

Note that, for the case when an advertising network is present on each and every page, $\hat{p} = p$ at the end of the series of sites visited. This means that the network was able to record each page visited by the user. This could easily be the page of advertising networks like Google that through different third-party services are ubiquitously present across the web.

We also define the profile of an ad, or third-party http request as the PMF $q =(q_1,\ldots, q_L)$, where $q_l$ is the percentage of tags belonging to the category $l$ which have been assigned to this specific advertising item. You can think of the ad profile as the PMF of the tag contained in every http request sent from the visited page to the advertising network (Listings: ~\ref{amazon}, ~\ref{krxd}, ~\ref{facebook}). This profile notes which tags the tracking network is using to identify the user and display some advertising content. Note that the ads profile, is calculated independently for each advertising network.

Both user and ads profiles can then be seen as normalised histograms of tags across categories of interest. Our profile model is in this extent equivalent to the tag clouds that numerous collaborative tagging services use to visualise which tags are being posted, collaboratively or individually by each user. A tag cloud, similarly to a histogram, is a visual representation in which tags are weighted according to their relevance.

In view of the assumptions described in the previous section, our privacy attacker boils down to an entity that aims to profile users by representing their interests in the form of normalised histograms, on the basis of a given categorisation.

We consider the third-party advertising network to operate like a recommendation system that suggest products or services that might be of interest for the user, based on their preferences. A recommendation system can be described as an information filtering system that seeks to predict if the user is interested or not in a particular resource. We assume that the ad server suggests advertising based on a measure of \emph{similarity} between what the user \emph{does} and what the network \emph{knows}. Furthermore, we consider tracking service to work in a feedback loop (Figure: ~\ref{fig:advertising-loop}). When a user surfs the web each tracker on the visited pages communicates with the advertising service, sending a number of parameters through HTTP requests. These contain the user preferences and browsing history which will be taken into consideration when ads are returned to display on the page. 

It is important to note that while it is safe to consider an advertising network as a recommendation system, we should also consider that a number of processes and interactions between the advertising networks, the website, and the ultimate advertiser, can influence the actual recommendation that is displayed to the user. Tracking services can in fact follow different strategies to recommend products to users. Some services display in page advertising where a bidding mechanism allow advertisers to compete for categories and spaces, other services might decide to target only specific categories, others might instead decide to target the visited page only.

\begin{figure}
\centerline{\epsfxsize=350pt\epsfbox{advertising-loop.png}}
\caption[Advertising services feedback loop]{Advertising services work in a feedback loop. The image illustrate how while a user surf a number of web pages, the service record their profile and adapts the returned advertising.}
\label{fig:advertising-loop}
\end{figure}

We measure the user profile, as previously described, as a histogram of their recorded preferences, and the advertising profile as a histogram of the ads that the user has received. We have considered a set of metric to measure how the advertising network is tracking the user profile, and how a page sends information to a tracking service by transmitting a partial user profile. 

In previous works\cite{puglisi2016web}~\cite{puglisi2015you} we used the \emph{1-norm}, \emph{2-norm} as measures of how the advertising profile, or the partial user profile, approximates the user profile. Please recall that the partial user profile is calculated by a given advertising network at a given moment on a series of pages visited.

We now introduce the normalised \emph{$\alpha$-norm} as the generalised variation \mathcal{GV} between two probability distributions, the partial and the genuine user profiles. Furthermore, we will introduce the \emph{KL-divergence} as a measure of how the partial profile approaches the genuine user profile. Please note that while we are defining our metrics between the partial user profile and the genuine user profile, the same assumptions holds, without loss of generality, if we compare the user's and the advertising profiles.

\subsubsection{Norm and generalised variation}

We define the $\alpha-norm$ between the partial profile as observed by an advertising platform and the genuine user profile as: 

$$ \| p - \hat{p} \|_\alpha = \sqrt[\alpha]{\sum_l{ {| p_l - \hat{p}_l |}^\alpha }} \quad  \text{with} \quad  \alpha \in [0, \infty] $$ 

The case for $\alpha = \infty$ is defined in the limit: 

$$\lim_{\alpha\to\infty} \| p - \hat{p} \|_\alpha = \lim_{\alpha\to\infty} \sqrt[\alpha]{\sum_l{ {| p_l - \hat{p}_l |}^\alpha }} \approx \max_l { | p_l - \hat{p}_l | } $$

The $\alpha-norm$ is a distance in $\mathbb{R}^L$ with the following properties:

\begin{itemize}
 \item Absolute homogeneity.
 \item Positive definite: $ \| p - \hat{p} \|_\alpha = 0 \Leftrightarrow p = \hat{p} $ and $ \| p - \hat{p} \|_\alpha = \sqrt[\alpha]{2}$ $\Leftrightarrow$  $p$ and $\hat{p}$ are orthogonal deltas. 
 \item Triangle equality.
\end{itemize}

For $\alpha = 1$ we define the \emph{1-norm} between the partial and the genuine user profiles as: 

$$ \| p - \hat{p} \|_1 = \sum_l{ | p_{l} - \hat{p}_{l} | }  $$

The \emph{1-norm} represent the average discrepancy between the two profiles. For $\alpha = 2$ we define the \emph{2-norm} as:

$$ \| p - \hat{p} \|_2 = \sqrt{\sum_l{ {| {p_{l} - \hat{p}_{l}} |}^2 }} $$

The \emph{2-norm} represents the Euclidean distance between the two distributions. When considering the \emph{2-norm} it is possible to highlight larger discrepancies on the set of categories analysed. An interesting property is that \emph{norms} are also nested. Hence:

$$ \| p - \hat{p} \|_\infty \leqslant \| p - \hat{p} \|_2 \leqslant \| p - \hat{p} \|_1 $$

We hence define the generalised variation $\text{GV}(p, \hat{p})$, based on $\alpha$-norm as:

$$ \text{GV}(p, \hat{p})_\alpha = \frac {1} {\sqrt[\alpha]{2}}  {\| p - \hat{p} \|}_\alpha =  \frac {1} {\sqrt[\alpha]{2}} \sqrt[\alpha]{{ \sum_l{ ( p_{l} - \hat{p}_{l})^\alpha } }} ,\quad  \alpha \in [1,\infty]$$

The coefficient $\frac {1} {\sqrt[\alpha]{2}}$ normalises the range of values of the \emph{$\alpha-norm$} in $[0, 1]$. Therefore, $\text{GV}(p, \hat{p})$ is a norm, is positive definite, absolutely homogeneous and satisfies the triangle inequality: 

\begin{itemize}
 \item $\text{GV}(p, \hat{p}) \geq 0 $ with equality if and only if $p = \hat{p}$
 \item $\text{GV}(p, \hat{p}) \leq 1$ with equality if and only if $p$ and $\hat{p}$ are orthogonal canonical vectors (discrete deltas).
\end{itemize}

Note that for $\alpha = 1$ the generalised variation $\text{GV}(p, \hat{p})$ is equal to the total variation $\text{TV}(p, \hat{p}) $:

$$ \text{TV}(p, \hat{p})= \frac {1} {2}  \| p - \hat{p} \|_1 =  \frac {1} {2} \sum_l{ | p_{l} - \hat{p}_{l} | } $$

For $\alpha = 2$ we have the normalised \emph{2-norm}:

$$ \text{GV}_2 = \frac {1} {\sqrt{2}}  {\| p - \hat{p} \|}_2 =  \frac {1} {\sqrt{2}} \sqrt{{ \sum_l{ | p_{l} - \hat{p}_{l}|^2 } }} $$

Finally, the case for $\alpha = \infty$, $\lim_{\alpha\to\infty} \text{GV}(p, \hat{p})_\alpha = \| p - \hat{p} \|_\infty $ between $p$ and $\hat{p}$. The reason is that for $\alpha \gg 1$ the greatest difference dominates in the sum $\sum_l{ {| p_l - \hat{p}_l |}^\alpha }$. Therefore $\lim_{\alpha\to\infty} \| p - \hat{p} \|_\alpha \approx \max_l { | p_l - \hat{p}_l | } $.

One might interpret these norms as $\alpha = 1$ been an average-case metric, $\alpha=\infty$ being a worst-case scenario, and $\alpha=2$ a robust middle ground.

\subsubsection{KL-Divergence}

Now we propose and justify an information-theoretic quantity as a measure of how the partial profile approaches the genuine user profile: the \emph{KL-divergence}. Suppose that we might interpret the profile $\hat{p}$ observed by a third-party tracking service, as a sequence of $L$ independent, identically distributed, drawings of a user's genuine profile of interest $p$. Then in accordance with the rationale proposed in ~\cite{parra2014measuring}~\cite{rebollo2011information}, we may argue that the probability $p(\hat{p})$, of a given observed profile is related to the KL-divergence between the empirical observation $\hat{p}$ and the ideal one $p$, as follows:

$$ - \frac {1}{L} \log{p(\hat{p})} \xrightarrow[L \to \infty]{} \textnormal{D}(\hat{p} \| p) $$

Informally this means $p(\hat{p}) \approx 2^{-\textnormal{L D}(\hat{p} \| p) } $. Note that small divergences will lead to likely outcomes, whereas large divergence associate with rare events. 

Note also that $\hat{p}$ is absolutely continuous with respect to $p$: $p_l = 0 \Rightarrow \hat{p}_l = 0$. Also $\hat{p} \ll p \iff  \textnormal{D}(\hat{p} \| p) < \infty$.

\section{Modelling the user's on-line footprint}
We model the user's activity as series of events belonging to a certain identity. Each event is a document containing different information. An event correspond to an action generated by the user or one of their devices. When a user visits a website or creates a post on a blog, an event is created. We can think of an event as a hypermedia document i.e. an object possibly containing graphics, audio, video, plain text and hyperlinks. We call the hyperlinks selectors and we use these to build the connections between the user's different identities or events. Each identity can be a profile or account that the user has created onto a service or platform, or just a collection of events, revealing something about the user. With account we mean an application account or a social network account, such as their LinkedIn or Facebook unique IDs. When the user visit a web page, or uses a web or mobile application, a series of events is generated and associated with the account. Some of these events are created by direct user's actions, others are created by code triggered indirectly by the user. 

While the user visits a webpage and reads its content a series of snippets of code and client side scripts are executed and information is transmitted to the page backend or some third-party server. Among the information transferred are a number of user preferences. These can be their geographical location, battery level of their current used device, browser preferences, or just their browsing history captured up to that point. Some or all of the meta and in page keywords used to describe the page are also transferred. We build the user profile by collecting the meta keywords expressed in web pages. We consider this a subset of the possible set of preferences that third-party advertising networks might be interested in collecting.

\subsection{Proposing a model of third-party requests on web pages}

When a user visits a web page, the browser sends an http request to the server to request a representation of the resource described through the url. The server provides the resource representation in the form of a html document and the browser parses it. The html document contains a number of links to other resources, such as JavaScript code, videos, audios or images (Figure: ~\ref{third-party}). Some of these can be stored on the same domain as the requested page, some may be requested to third-party services. Such is the case of services like Google Analytics, share buttons from different social networks, or advertising banners. Together with the http request, a number of parameters are included. These contains keywords, users? preferences, information regarding the user device and session, in page information sent to the third-party service from the website or application.

\setcounter{figure}{1}
\begin{figure}
\centerline{\epsfxsize=350pt\epsfbox{tracker-request.png}}
\caption{Trackers on web pages make third-party http requests to advertising services. These return ads content tailored to the user web history or expressed preferences.}
\label{third-party}
\end{figure}

When a third-party request is performed by the visited page, we store the parameters passed and if the call belongs to a known tracking network we categorise the corresponding keywords. Also when a request is made, we store a direct link between the page and a tracking domain, such as google.com. This results in a graph model of tracking networks and how these are connected to pages (Figure: ~\ref{graph-map}). The graph model allows us to understand the underling network structure of tracking networks and how these are pervasively following users across their visits. In fact, every time we discover which tracking services are active on a certain website, we can create an indirect link between the user and the tracker.

\setcounter{figure}{2}
\begin{figure}
\centerline{\epsfxsize=350pt\epsfbox{graph-map.png}}
\caption{The graph shows how known trackers are connected to visited pages and therefore how these are able to follow users across different websites.}
\label{graph-map}
\end{figure}

\subsection{Network structure metrics}

We said that advertising networks or privacy attackers need to be able to \emph{follow} the user across as many websites as possible in order to profile their interests. This naturally translates onto a graph model where each page is directly connected to its active trackers (Figure: ~\ref{graph-map}).  
We therefore considered a set of metrics that can uncover the underlying network structure of tracking service. The first of the metrics considered is the average degree of the neighbourhood. The average degree of the neighbourhood of each node is a good indication of how many pages are connected to a certain advertising service or tracking domain.

The average degree of the neighbourhood of a node $i$ is calculated as:

$$ \langle k_{nn,i} \rangle= \frac{1}{| N(i) |} \sum_{j \in N(i) } {k_j} $$

Where $N(i)$ are the neighbours of node $i$ and $k_j$ is the degree of node $j$ which belongs to $N(i)$.

If a certain tracker domain is connected to the majority of the page visited by a certain user, this means that they have been able to collect the user's preferences and reading activities across a number of websites. The more a tracker domain is connected, the more the user might consider this a \emph{risk} for their privacy. We used the average degree of the neighbourhood of a tracker to rank tracker domains.

To describe the resulting network structure we also calculated the average scalar assortativity coefficient~\cite{newman2002assortative} defined as:

$$ r = \frac{\sum_{xy} xy(e_{xy} - a_x b_y)}{\sigma_a\sigma_b} $$   

Where $a_x=\sum_ye_{xy}$ and $b_y=\sum_xe_{xy}$, and $e_{xy}$ is the fraction of edges from a vertex of type x to a vertex of type y.

We also generated a partition of SBM and nested SBM of the resulting graph employing an agglomerative multilevel Markov chain Monte Carlo (MCMC) algorithm as described in~\cite{peixoto2014efficient}~\cite{peixoto2013parsimonious}\cite{peixoto2012entropy}. The idea behind using SBM to describe the network structure of identified trackers is to be able to identify similar trackers and to understand if trackers belonging to the same domain or that exhibit similar behaviour can be grouped based on network properties.

